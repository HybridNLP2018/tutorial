{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de 05_interlinking_and_curation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "p9jOxZnLRnfv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# KG curation, interlinking and multilinguality\n",
        "\n",
        "In this notebook we look at how embeddings can be used in curation of Knowledge Graphs, in particular in tasks such as graph completion and alignment."
      ]
    },
    {
      "metadata": {
        "id": "jSZqGQmCRnfw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## KG completion\n",
        "\n",
        "Knowledge Graph completion is the task of predicting whether an existing, incomplete, graph should add a vertix between two specific nodes. For example, in DBpedia, you may want to generate new links between pages and categories.\n",
        "\n",
        "Although embeddings for KGs are more suitable for this kind of task, word (and cross-modal) embeddings can also provide valuable input."
      ]
    },
    {
      "metadata": {
        "id": "lOg8pKEbRnfx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Multilingual KG alignment\n",
        "\n",
        "If you have multiple KGs that need to be aligned, you may be able to use *embedding alignment techniques*."
      ]
    },
    {
      "metadata": {
        "id": "BghVzkZBRnfy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Linear alignment\n",
        "The most straightforward alignment between two embedding spaces can be achieved by using a *translation matrix*, as shown in (Mikolov et al, 2013). Basically, a translation matrix W is such that **z=Wx**, where z is a vector belonging to the target vector space and x is the equivalent in the source.\n",
        "\n",
        "To calculate the translation matrix, you need a **dictionary** that provides mappings for a subset of your vocabularies.\n",
        "\n",
        "You can then use existing linear algorithms to calculate the pseudo inverse.\n",
        "\n",
        "For best results, it is recommended to use parallel corpora (so that the same words are encoded in similar ways) or very large corpora.\n",
        "\n",
        "In the following example, we use pre-generated embeddings for the most frequent 5K lemmas in the *United Nations parallel corpus*. \n",
        "\n",
        "We first load the vectors. "
      ]
    },
    {
      "metadata": {
        "id": "qkMJsaOeRnfz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "49932474-28d6-4d62-81ad-fd638742512d"
      },
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/HybridNLP2018/tutorial.git\n",
        "from tutorial.scripts.swivel import vecs\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'tutorial'...\n",
            "remote: Enumerating objects: 592, done.\u001b[K\n",
            "remote: Total 592 (delta 0), reused 0 (delta 0), pack-reused 592\u001b[K\n",
            "Receiving objects: 100% (592/592), 47.53 MiB | 39.32 MiB/s, done.\n",
            "Resolving deltas: 100% (337/337), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lYPurqdTRnf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "05e6a2b7-0107-4a01-e43b-009b35b0e744"
      },
      "cell_type": "code",
      "source": [
        "en_path = '/content/tutorial/datasamples/UNv1.0/en_lemma_5k/'\n",
        "es_path = '/content/tutorial/datasamples/UNv1.0/es_lemma_5k/'\n",
        "en_vecs = vecs.Vecs(en_path + 'vocab.txt', \n",
        "            en_path + 'vecs.bin')\n",
        "es_vecs = vecs.Vecs(es_path + 'vocab.txt',\n",
        "            es_path + 'vecs.bin')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Opening vector with expected size 5000 from file /content/tutorial/datasamples/UNv1.0/en_lemma_5k/vocab.txt\n",
            "vocab size 5000 (unique 5000)\n",
            "read rows\n",
            "Opening vector with expected size 5000 from file /content/tutorial/datasamples/UNv1.0/es_lemma_5k/vocab.txt\n",
            "vocab size 5000 (unique 5000)\n",
            "read rows\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zLn1n1rgRnf9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's check a couple of words in each embedding space as we have done in previous notebooks:"
      ]
    },
    {
      "metadata": {
        "id": "e94qCmfMRngB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "63ea1cad-0b85-49f2-b9c4-e7228f639c41"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(en_vecs.k_neighbors('knowledge'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosim</th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>knowledge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.631812</td>\n",
              "      <td>skill</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.603642</td>\n",
              "      <td>know-how</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.574704</td>\n",
              "      <td>sharing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.537305</td>\n",
              "      <td>information</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.536732</td>\n",
              "      <td>learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.534542</td>\n",
              "      <td>innovation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.533146</td>\n",
              "      <td>technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.531260</td>\n",
              "      <td>understanding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.513664</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      cosim           word\n",
              "0  1.000000      knowledge\n",
              "1  0.631812          skill\n",
              "2  0.603642       know-how\n",
              "3  0.574704        sharing\n",
              "4  0.537305    information\n",
              "5  0.536732       learning\n",
              "6  0.534542     innovation\n",
              "7  0.533146     technology\n",
              "8  0.531260  understanding\n",
              "9  0.513664        science"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "J-Qcdu4KRngF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "512b6e56-e66f-4724-9e4d-b29d04be52ce"
      },
      "cell_type": "code",
      "source": [
        "pd.DataFrame(es_vecs.k_neighbors('conocimiento'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosim</th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>conocimiento</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.780866</td>\n",
              "      <td>conocimientos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.603392</td>\n",
              "      <td>aptitud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.586549</td>\n",
              "      <td>comprensión</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.557678</td>\n",
              "      <td>intercambio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.537809</td>\n",
              "      <td>capacidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.526911</td>\n",
              "      <td>difusión</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.525315</td>\n",
              "      <td>científico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.521962</td>\n",
              "      <td>información</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.516031</td>\n",
              "      <td>fomentar</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      cosim           word\n",
              "0  1.000000   conocimiento\n",
              "1  0.780866  conocimientos\n",
              "2  0.603392        aptitud\n",
              "3  0.586549    comprensión\n",
              "4  0.557678    intercambio\n",
              "5  0.537809      capacidad\n",
              "6  0.526911       difusión\n",
              "7  0.525315     científico\n",
              "8  0.521962    información\n",
              "9  0.516031       fomentar"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "_tf7DdMjRngJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Besides the embeddings for English and Spanish, we also provide a **dictionary** that was generated automatically to map 1K English lemmas into Spanish."
      ]
    },
    {
      "metadata": {
        "id": "QARuMB5ZRngK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a7893868-5eb3-4470-e0ef-260b413d4ed0"
      },
      "cell_type": "code",
      "source": [
        "%ls /content/tutorial/datasamples/UNv1.0/\n",
        "en2es_dict_path = '/content/tutorial/datasamples/UNv1.0/en2es-lemma-dict-1k.txt'\n",
        "!head -n 5 {en2es_dict_path}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en2es-lemma-dict-1k.txt  \u001b[0m\u001b[01;34men_lemma_5k\u001b[0m/  \u001b[01;34mes_lemma_5k\u001b[0m/\n",
            "be:ser\n",
            "by:por conducto de\n",
            "report:informe\n",
            "state:estado\n",
            "country:estado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SY3EHhGyRngP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's load the dictionary into a python object."
      ]
    },
    {
      "metadata": {
        "id": "pp_O0DrtRngP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_dict(path, invert=False):\n",
        "    result = {}\n",
        "    with open(path, 'r') as lines:\n",
        "        for line in lines:\n",
        "            (key, val) = line.split(':')\n",
        "            if invert:\n",
        "                result[val.strip('\\n')] = key\n",
        "            else: \n",
        "                result[key] = val.strip('\\n')\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xFAxGEQIRngS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bec34490-f2fb-4552-9bb9-d646f17462bb"
      },
      "cell_type": "code",
      "source": [
        "en2es = load_dict(en2es_dict_path)\n",
        "es2en = load_dict(en2es_dict_path, invert=True)\n",
        "len(en2es), len(es2en)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 882)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "iTdEnUT2RngW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can see from the reported numbers that some English lemmas were mapped to the same Spanish lemma."
      ]
    },
    {
      "metadata": {
        "id": "aInnQFzkRngX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's inspect some of the entries in the dictionary:"
      ]
    },
    {
      "metadata": {
        "id": "6QqB6oDbRngZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "a728f6ff-0760-4608-d30c-206b18035e80"
      },
      "cell_type": "code",
      "source": [
        "min = 5\n",
        "max = min + 5\n",
        "for en in list(en2es)[min:max]:\n",
        "    print(en, '->', en2es[en])\n",
        "print('')\n",
        "for es in list(es2en)[min:max]:\n",
        "    print(es, '->', es2en[es])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "also -> también\n",
            "provide -> proporcionar\n",
            "all -> todo\n",
            "development -> intensificación\n",
            "other -> otro\n",
            "\n",
            "proporcionar -> supply\n",
            "todo -> all\n",
            "intensificación -> development\n",
            "otro -> another\n",
            "programar -> programme\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5SFprFqeRngc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to create the translation matrix, we need to create two **aligned** matrices:\n",
        "  - $M_{en}$ will contain $n$ English embeddings from the dictionary\n",
        "  - $M_{es}$ will contain $n$ Spanish embeddings from the dictionary\n",
        "  \n",
        "However, since the dictionary was generated automatically, it may be the case that some of the entries in the dictionary are not in the English or Spanish vocabularies. We only need the `id`s in the respective `vecs`:"
      ]
    },
    {
      "metadata": {
        "id": "FuUGBGaSRngf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a61e142e-948e-418f-c5ea-87753be1442c"
      },
      "cell_type": "code",
      "source": [
        "en_dict_ids = []\n",
        "es_dict_ids = []\n",
        "es_dict_voc = []\n",
        "for es in es2en:\n",
        "    es_id = es_vecs.word_to_idx.get(es)\n",
        "    en_id = en_vecs.word_to_idx.get(es2en[es])\n",
        "    if en_id and es_id :\n",
        "        es_dict_voc.append(es)\n",
        "        en_dict_ids.append(en_id)\n",
        "        es_dict_ids.append(es_id)\n",
        "print(len(en_dict_ids), len(es_dict_ids))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "477 477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JjhmKG2RRngk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From the 1K dictionary entries, only $477$ pairs were both in the English and the Spanish `vecs`. In order to verify that the translation works, we can split this into $450$ pairs that we will use to calculate the translation matrix and we keep the remaining $27$ for testing:"
      ]
    },
    {
      "metadata": {
        "id": "f2uSwzgcRngk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcb78770-685f-4a54-c670-bf89158d5f27"
      },
      "cell_type": "code",
      "source": [
        "train_en_dict_ids = en_dict_ids[:450]\n",
        "train_es_dict_ids = es_dict_ids[:450]\n",
        "test_en_ids = en_dict_ids[450:] \n",
        "test_es_ids = es_dict_ids[450:]\n",
        "print(len(train_en_dict_ids), len(test_en_ids))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "450 27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bfXNUpslRngp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before calculating the translation matrix, let's verify that we need one. We chose 3 example words:\n",
        "  - *conocimiento*  and *proporcionar* are in the in the training set, \n",
        "  - *tema* is in the test set\n",
        "  \n",
        "For each word, we get:\n",
        " - the $5$ Spanish neighbors for the English vector\n",
        " - the $5$ Spanish neighbors for the Spanish translation according to the dictionary"
      ]
    },
    {
      "metadata": {
        "id": "xmVvj_UORngq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1207
        },
        "outputId": "81d71827-39cc-4b54-dc34-3c3c6e5ac986"
      },
      "cell_type": "code",
      "source": [
        "es_examples = ['conocimientos', 'proporcionar', 'tema']\n",
        "from IPython.display import display\n",
        "for i, es in enumerate(es_examples):\n",
        "    print(es, '->', es2en[es])\n",
        "    print('top k for Spanish vector in English vector space:')\n",
        "    k = 5\n",
        "    df1 = pd.DataFrame(en_vecs.k_neighbors(es_vecs.lookup(es), k=k, result_key_suffix='_es_vec'))\n",
        "    print('top k for English translation in English vector space:')\n",
        "    df2 = pd.DataFrame(en_vecs.k_neighbors(es2en[es], k=k, result_key_suffix='_en'))\n",
        "    df3 = pd.concat([df1, df2], axis=1)\n",
        "    #print(df3)\n",
        "    display(df3)\n",
        "    print('')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conocimientos -> knowledge\n",
            "top k for Spanish vector in English vector space:\n",
            "top k for English translation in English vector space:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosim_es_vec</th>\n",
              "      <th>word_es_vec</th>\n",
              "      <th>cosim_en</th>\n",
              "      <th>word_en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.195447</td>\n",
              "      <td>jewish</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>knowledge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.194971</td>\n",
              "      <td>concept</td>\n",
              "      <td>0.631812</td>\n",
              "      <td>skill</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.185432</td>\n",
              "      <td>once</td>\n",
              "      <td>0.603642</td>\n",
              "      <td>know-how</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.183663</td>\n",
              "      <td>theme</td>\n",
              "      <td>0.574704</td>\n",
              "      <td>sharing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.183211</td>\n",
              "      <td>cross</td>\n",
              "      <td>0.537305</td>\n",
              "      <td>information</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.175961</td>\n",
              "      <td>sister</td>\n",
              "      <td>0.536732</td>\n",
              "      <td>learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.175771</td>\n",
              "      <td>saudi</td>\n",
              "      <td>0.534542</td>\n",
              "      <td>innovation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.172918</td>\n",
              "      <td>business</td>\n",
              "      <td>0.533146</td>\n",
              "      <td>technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.169612</td>\n",
              "      <td>united kingdom</td>\n",
              "      <td>0.531260</td>\n",
              "      <td>understanding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.165519</td>\n",
              "      <td>pronounce</td>\n",
              "      <td>0.513664</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cosim_es_vec     word_es_vec  cosim_en        word_en\n",
              "0      0.195447          jewish  1.000000      knowledge\n",
              "1      0.194971         concept  0.631812          skill\n",
              "2      0.185432            once  0.603642       know-how\n",
              "3      0.183663           theme  0.574704        sharing\n",
              "4      0.183211           cross  0.537305    information\n",
              "5      0.175961          sister  0.536732       learning\n",
              "6      0.175771           saudi  0.534542     innovation\n",
              "7      0.172918        business  0.533146     technology\n",
              "8      0.169612  united kingdom  0.531260  understanding\n",
              "9      0.165519       pronounce  0.513664        science"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "proporcionar -> supply\n",
            "top k for Spanish vector in English vector space:\n",
            "top k for English translation in English vector space:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosim_es_vec</th>\n",
              "      <th>word_es_vec</th>\n",
              "      <th>cosim_en</th>\n",
              "      <th>word_en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.222659</td>\n",
              "      <td>candidate</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>supply</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.195560</td>\n",
              "      <td>arrest warrant</td>\n",
              "      <td>0.748887</td>\n",
              "      <td>supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.187525</td>\n",
              "      <td>king</td>\n",
              "      <td>0.542984</td>\n",
              "      <td>spare part</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.185336</td>\n",
              "      <td>trading</td>\n",
              "      <td>0.537591</td>\n",
              "      <td>purchase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.183837</td>\n",
              "      <td>selection</td>\n",
              "      <td>0.500451</td>\n",
              "      <td>fuel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.183204</td>\n",
              "      <td>select</td>\n",
              "      <td>0.499277</td>\n",
              "      <td>medical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.179192</td>\n",
              "      <td>commit</td>\n",
              "      <td>0.483074</td>\n",
              "      <td>transportation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.179038</td>\n",
              "      <td>pool</td>\n",
              "      <td>0.482907</td>\n",
              "      <td>ration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.174210</td>\n",
              "      <td>rule</td>\n",
              "      <td>0.480970</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.172928</td>\n",
              "      <td>business plan</td>\n",
              "      <td>0.470521</td>\n",
              "      <td>shortage</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cosim_es_vec     word_es_vec  cosim_en         word_en\n",
              "0      0.222659       candidate  1.000000          supply\n",
              "1      0.195560  arrest warrant  0.748887        supplies\n",
              "2      0.187525            king  0.542984      spare part\n",
              "3      0.185336         trading  0.537591        purchase\n",
              "4      0.183837       selection  0.500451            fuel\n",
              "5      0.183204          select  0.499277         medical\n",
              "6      0.179192          commit  0.483074  transportation\n",
              "7      0.179038            pool  0.482907          ration\n",
              "8      0.174210            rule  0.480970         service\n",
              "9      0.172928   business plan  0.470521        shortage"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "tema -> theme\n",
            "top k for Spanish vector in English vector space:\n",
            "top k for English translation in English vector space:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosim_es_vec</th>\n",
              "      <th>word_es_vec</th>\n",
              "      <th>cosim_en</th>\n",
              "      <th>word_en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.204613</td>\n",
              "      <td>accumulate</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>theme</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.202783</td>\n",
              "      <td>per cent</td>\n",
              "      <td>0.695908</td>\n",
              "      <td>topic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.190149</td>\n",
              "      <td>wood</td>\n",
              "      <td>0.636073</td>\n",
              "      <td>panel discussion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.179899</td>\n",
              "      <td>go on</td>\n",
              "      <td>0.634660</td>\n",
              "      <td>thematic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.174604</td>\n",
              "      <td>than</td>\n",
              "      <td>0.612211</td>\n",
              "      <td>cross-cutting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.174476</td>\n",
              "      <td>ten</td>\n",
              "      <td>0.565744</td>\n",
              "      <td>sustainable development</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.171583</td>\n",
              "      <td>accumulation</td>\n",
              "      <td>0.562757</td>\n",
              "      <td>round table</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.167805</td>\n",
              "      <td>correctly</td>\n",
              "      <td>0.547525</td>\n",
              "      <td>discussion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.167107</td>\n",
              "      <td>vision</td>\n",
              "      <td>0.541553</td>\n",
              "      <td>high-level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.166883</td>\n",
              "      <td>scene</td>\n",
              "      <td>0.536971</td>\n",
              "      <td>focus</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cosim_es_vec   word_es_vec  cosim_en                  word_en\n",
              "0      0.204613    accumulate  1.000000                    theme\n",
              "1      0.202783      per cent  0.695908                    topic\n",
              "2      0.190149          wood  0.636073         panel discussion\n",
              "3      0.179899         go on  0.634660                 thematic\n",
              "4      0.174604          than  0.612211            cross-cutting\n",
              "5      0.174476           ten  0.565744  sustainable development\n",
              "6      0.171583  accumulation  0.562757              round table\n",
              "7      0.167805     correctly  0.547525               discussion\n",
              "8      0.167107        vision  0.541553               high-level\n",
              "9      0.166883         scene  0.536971                    focus"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q3B4UtsARngu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Clearly, simply using the Spanish vector in the English space does not work. Let's get the matrices:"
      ]
    },
    {
      "metadata": {
        "id": "_11t6J12Rngv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5dbd707f-8bab-41b2-ee69-dc0e9e533564"
      },
      "cell_type": "code",
      "source": [
        "m_en = en_vecs.vecs[train_en_dict_ids]\n",
        "m_es = es_vecs.vecs[train_es_dict_ids]\n",
        "print(m_en.shape, m_es.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(450, 300) (450, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YrK4hSbTRngz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As expected, we get two matrices of $450 \\times 300$, since embeddings are of dimension $300$ and we have $450$ training examples. Now, we can calculate the translation matrix and define a method for linearly translating a point in the Spanish embedding space into a point in the English embedding space."
      ]
    },
    {
      "metadata": {
        "id": "R5N3n_GtRng0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06807c72-504b-4d12-ca51-8c1c2ded0579"
      },
      "cell_type": "code",
      "source": [
        "tm_es2en = np.linalg.pinv(m_es).dot(m_en)\n",
        "def es_vec_to_en_vec(es_vec):\n",
        "    return np.dot(es_vec, tm_es2en)\n",
        "print(tm_es2en.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(300, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-V3UZ_mNRng4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As we can see, the translation matrix is just a $300 \\times 300$ matrix.\n",
        "\n",
        "Now that we have the translation matrix, let's inspect the example words to see how it performs:"
      ]
    },
    {
      "metadata": {
        "id": "Ul7kLNcnRng5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1260
        },
        "outputId": "06ad5dbb-9607-48fa-d685-1f1e369b72c5"
      },
      "cell_type": "code",
      "source": [
        "for i, es in enumerate(es_examples):\n",
        "    print(es, '->', es2en[es])\n",
        "    k = 5\n",
        "    print('\\t%s: Spanish vector for \"%s\" in English vector space' % ('es_vec', es))\n",
        "    df1 = pd.DataFrame(en_vecs.k_neighbors(es_vecs.lookup(es), k=k, result_key_suffix='_es_vec'))\n",
        "    print('\\t%s: English vector for \"%s\" in English vector space' % ('en', es2en[es]))\n",
        "    df2 = pd.DataFrame(en_vecs.k_neighbors(es2en[es], k=k, result_key_suffix='_en'))\n",
        "    print('\\t%s: Spanish vector for \"%s\" *mapped* to English vector space using tm_es2en' % ('tm_es_vec', es))\n",
        "    df3 = pd.DataFrame(en_vecs.k_neighbors(es_vec_to_en_vec(es_vecs.lookup(es)), k=k, result_key_suffix='_tm_es_vec'))\n",
        "    df4 = pd.concat([df1,df2,df3], axis=1)\n",
        "    display(df4)\n",
        "    print('')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conocimientos -> knowledge\n",
            "\tes_vec: Spanish vector for \"conocimientos\" in English vector space\n",
            "\ten: English vector for \"knowledge\" in English vector space\n",
            "\ttm_es_vec: Spanish vector for \"conocimientos\" *mapped* to English vector space using tm_es2en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosim_es_vec</th>\n",
              "      <th>word_es_vec</th>\n",
              "      <th>cosim_en</th>\n",
              "      <th>word_en</th>\n",
              "      <th>cosim_tm_es_vec</th>\n",
              "      <th>word_tm_es_vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.195447</td>\n",
              "      <td>jewish</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>knowledge</td>\n",
              "      <td>0.894568</td>\n",
              "      <td>knowledge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.194971</td>\n",
              "      <td>concept</td>\n",
              "      <td>0.631812</td>\n",
              "      <td>skill</td>\n",
              "      <td>0.652778</td>\n",
              "      <td>skill</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.185432</td>\n",
              "      <td>once</td>\n",
              "      <td>0.603642</td>\n",
              "      <td>know-how</td>\n",
              "      <td>0.597379</td>\n",
              "      <td>know-how</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.183663</td>\n",
              "      <td>theme</td>\n",
              "      <td>0.574704</td>\n",
              "      <td>sharing</td>\n",
              "      <td>0.581842</td>\n",
              "      <td>technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.183211</td>\n",
              "      <td>cross</td>\n",
              "      <td>0.537305</td>\n",
              "      <td>information</td>\n",
              "      <td>0.568328</td>\n",
              "      <td>capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.175961</td>\n",
              "      <td>sister</td>\n",
              "      <td>0.536732</td>\n",
              "      <td>learning</td>\n",
              "      <td>0.566806</td>\n",
              "      <td>information</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.175771</td>\n",
              "      <td>saudi</td>\n",
              "      <td>0.534542</td>\n",
              "      <td>innovation</td>\n",
              "      <td>0.564072</td>\n",
              "      <td>technical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.172918</td>\n",
              "      <td>business</td>\n",
              "      <td>0.533146</td>\n",
              "      <td>technology</td>\n",
              "      <td>0.563809</td>\n",
              "      <td>sharing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.169612</td>\n",
              "      <td>united kingdom</td>\n",
              "      <td>0.531260</td>\n",
              "      <td>understanding</td>\n",
              "      <td>0.551107</td>\n",
              "      <td>scientific</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.165519</td>\n",
              "      <td>pronounce</td>\n",
              "      <td>0.513664</td>\n",
              "      <td>science</td>\n",
              "      <td>0.545087</td>\n",
              "      <td>training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cosim_es_vec     word_es_vec  cosim_en        word_en  cosim_tm_es_vec  \\\n",
              "0      0.195447          jewish  1.000000      knowledge         0.894568   \n",
              "1      0.194971         concept  0.631812          skill         0.652778   \n",
              "2      0.185432            once  0.603642       know-how         0.597379   \n",
              "3      0.183663           theme  0.574704        sharing         0.581842   \n",
              "4      0.183211           cross  0.537305    information         0.568328   \n",
              "5      0.175961          sister  0.536732       learning         0.566806   \n",
              "6      0.175771           saudi  0.534542     innovation         0.564072   \n",
              "7      0.172918        business  0.533146     technology         0.563809   \n",
              "8      0.169612  united kingdom  0.531260  understanding         0.551107   \n",
              "9      0.165519       pronounce  0.513664        science         0.545087   \n",
              "\n",
              "  word_tm_es_vec  \n",
              "0      knowledge  \n",
              "1          skill  \n",
              "2       know-how  \n",
              "3     technology  \n",
              "4       capacity  \n",
              "5    information  \n",
              "6      technical  \n",
              "7        sharing  \n",
              "8     scientific  \n",
              "9       training  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "proporcionar -> supply\n",
            "\tes_vec: Spanish vector for \"proporcionar\" in English vector space\n",
            "\ten: English vector for \"supply\" in English vector space\n",
            "\ttm_es_vec: Spanish vector for \"proporcionar\" *mapped* to English vector space using tm_es2en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosim_es_vec</th>\n",
              "      <th>word_es_vec</th>\n",
              "      <th>cosim_en</th>\n",
              "      <th>word_en</th>\n",
              "      <th>cosim_tm_es_vec</th>\n",
              "      <th>word_tm_es_vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.222659</td>\n",
              "      <td>candidate</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>supply</td>\n",
              "      <td>0.742566</td>\n",
              "      <td>supply</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.195560</td>\n",
              "      <td>arrest warrant</td>\n",
              "      <td>0.748887</td>\n",
              "      <td>supplies</td>\n",
              "      <td>0.577888</td>\n",
              "      <td>supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.187525</td>\n",
              "      <td>king</td>\n",
              "      <td>0.542984</td>\n",
              "      <td>spare part</td>\n",
              "      <td>0.442933</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.185336</td>\n",
              "      <td>trading</td>\n",
              "      <td>0.537591</td>\n",
              "      <td>purchase</td>\n",
              "      <td>0.427956</td>\n",
              "      <td>provision</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.183837</td>\n",
              "      <td>selection</td>\n",
              "      <td>0.500451</td>\n",
              "      <td>fuel</td>\n",
              "      <td>0.423716</td>\n",
              "      <td>provide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.183204</td>\n",
              "      <td>select</td>\n",
              "      <td>0.499277</td>\n",
              "      <td>medical</td>\n",
              "      <td>0.419686</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.179192</td>\n",
              "      <td>commit</td>\n",
              "      <td>0.483074</td>\n",
              "      <td>transportation</td>\n",
              "      <td>0.419077</td>\n",
              "      <td>purchase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.179038</td>\n",
              "      <td>pool</td>\n",
              "      <td>0.482907</td>\n",
              "      <td>ration</td>\n",
              "      <td>0.411310</td>\n",
              "      <td>medical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.174210</td>\n",
              "      <td>rule</td>\n",
              "      <td>0.480970</td>\n",
              "      <td>service</td>\n",
              "      <td>0.411244</td>\n",
              "      <td>spare part</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.172928</td>\n",
              "      <td>business plan</td>\n",
              "      <td>0.470521</td>\n",
              "      <td>shortage</td>\n",
              "      <td>0.401046</td>\n",
              "      <td>transportation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cosim_es_vec     word_es_vec  cosim_en         word_en  cosim_tm_es_vec  \\\n",
              "0      0.222659       candidate  1.000000          supply         0.742566   \n",
              "1      0.195560  arrest warrant  0.748887        supplies         0.577888   \n",
              "2      0.187525            king  0.542984      spare part         0.442933   \n",
              "3      0.185336         trading  0.537591        purchase         0.427956   \n",
              "4      0.183837       selection  0.500451            fuel         0.423716   \n",
              "5      0.183204          select  0.499277         medical         0.419686   \n",
              "6      0.179192          commit  0.483074  transportation         0.419077   \n",
              "7      0.179038            pool  0.482907          ration         0.411310   \n",
              "8      0.174210            rule  0.480970         service         0.411244   \n",
              "9      0.172928   business plan  0.470521        shortage         0.401046   \n",
              "\n",
              "   word_tm_es_vec  \n",
              "0          supply  \n",
              "1        supplies  \n",
              "2            food  \n",
              "3       provision  \n",
              "4         provide  \n",
              "5         service  \n",
              "6        purchase  \n",
              "7         medical  \n",
              "8      spare part  \n",
              "9  transportation  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "tema -> theme\n",
            "\tes_vec: Spanish vector for \"tema\" in English vector space\n",
            "\ten: English vector for \"theme\" in English vector space\n",
            "\ttm_es_vec: Spanish vector for \"tema\" *mapped* to English vector space using tm_es2en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosim_es_vec</th>\n",
              "      <th>word_es_vec</th>\n",
              "      <th>cosim_en</th>\n",
              "      <th>word_en</th>\n",
              "      <th>cosim_tm_es_vec</th>\n",
              "      <th>word_tm_es_vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.204613</td>\n",
              "      <td>accumulate</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>theme</td>\n",
              "      <td>0.772404</td>\n",
              "      <td>theme</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.202783</td>\n",
              "      <td>per cent</td>\n",
              "      <td>0.695908</td>\n",
              "      <td>topic</td>\n",
              "      <td>0.610194</td>\n",
              "      <td>topic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.190149</td>\n",
              "      <td>wood</td>\n",
              "      <td>0.636073</td>\n",
              "      <td>panel discussion</td>\n",
              "      <td>0.602442</td>\n",
              "      <td>session</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.179899</td>\n",
              "      <td>go on</td>\n",
              "      <td>0.634660</td>\n",
              "      <td>thematic</td>\n",
              "      <td>0.585061</td>\n",
              "      <td>discussion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.174604</td>\n",
              "      <td>than</td>\n",
              "      <td>0.612211</td>\n",
              "      <td>cross-cutting</td>\n",
              "      <td>0.576319</td>\n",
              "      <td>thematic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.174476</td>\n",
              "      <td>ten</td>\n",
              "      <td>0.565744</td>\n",
              "      <td>sustainable development</td>\n",
              "      <td>0.550427</td>\n",
              "      <td>agenda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.171583</td>\n",
              "      <td>accumulation</td>\n",
              "      <td>0.562757</td>\n",
              "      <td>round table</td>\n",
              "      <td>0.549161</td>\n",
              "      <td>high-level</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.167805</td>\n",
              "      <td>correctly</td>\n",
              "      <td>0.547525</td>\n",
              "      <td>discussion</td>\n",
              "      <td>0.539559</td>\n",
              "      <td>panel discussion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.167107</td>\n",
              "      <td>vision</td>\n",
              "      <td>0.541553</td>\n",
              "      <td>high-level</td>\n",
              "      <td>0.538621</td>\n",
              "      <td>meeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.166883</td>\n",
              "      <td>scene</td>\n",
              "      <td>0.536971</td>\n",
              "      <td>focus</td>\n",
              "      <td>0.533962</td>\n",
              "      <td>discuss</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cosim_es_vec   word_es_vec  cosim_en                  word_en  \\\n",
              "0      0.204613    accumulate  1.000000                    theme   \n",
              "1      0.202783      per cent  0.695908                    topic   \n",
              "2      0.190149          wood  0.636073         panel discussion   \n",
              "3      0.179899         go on  0.634660                 thematic   \n",
              "4      0.174604          than  0.612211            cross-cutting   \n",
              "5      0.174476           ten  0.565744  sustainable development   \n",
              "6      0.171583  accumulation  0.562757              round table   \n",
              "7      0.167805     correctly  0.547525               discussion   \n",
              "8      0.167107        vision  0.541553               high-level   \n",
              "9      0.166883         scene  0.536971                    focus   \n",
              "\n",
              "   cosim_tm_es_vec    word_tm_es_vec  \n",
              "0         0.772404             theme  \n",
              "1         0.610194             topic  \n",
              "2         0.602442           session  \n",
              "3         0.585061        discussion  \n",
              "4         0.576319          thematic  \n",
              "5         0.550427            agenda  \n",
              "6         0.549161        high-level  \n",
              "7         0.539559  panel discussion  \n",
              "8         0.538621           meeting  \n",
              "9         0.533962           discuss  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-U1QXjdnRng9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Non-linear alignment\n",
        "\n",
        "The linear alignment seems to work OK for this set of embeddings. In our experience, when dealing with larger vocabularies (and vocabularies mixing lemmas and concepts), this approach does not scale, since the number of parameters is limited to the $d \\times d$ translation matrix.\n",
        "\n",
        "For such cases it is possible to follow the same approach, but instead of deriving a pseudo-inverse matrix, we train a neural network to learn a non-linear translation function. The non-linearities can be introduced by using activation functions such as ReLUs.\n",
        "\n",
        "See  [Towards a Vecsigrafo: Portable Semantics in Knowledge-based Text Analytics](https://pdfs.semanticscholar.org/b0d6/197940d8f1a5fa0d7474bd9a94bd9e44a0ee.pdf) for more details."
      ]
    },
    {
      "metadata": {
        "id": "Ia78X0o7Rng-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Example: Cross-modal embeddings\n",
        "\n",
        "In [Thoma, S., Rettinger, A., & Both, F. (2017). Towards Holistic Concept Representations: Embedding Relational Knowledge, Visual Attributes, and Distributional Word Semantics. In International Semantic Web Conference. Vienna, Austria.](https://pdfs.semanticscholar.org/413e/b0b519ac18ec86aaa290c86553291fae7ea2.pdf), a cross-modal embedding is generated for a 1538 concepts.  \n",
        "\n",
        "![Cross-modal embeddings](https://github.com/HybridNLP2018/tutorial/blob/master/images/cross-modal-embedding.PNG?raw=1)\n",
        "\n",
        "As part of their evaluations, the authors studied the problem of entity-type prediction (a subtask of KG completion), using a subgraph of DBpedia that provided coverage for the 1538 concepts. Their results were:\n",
        "\n",
        "![TriM1538 entity-type prediction results](https://github.com/HybridNLP2018/tutorial/blob/master/images/TriM1538-entity-type-pred-results.PNG?raw=1)\n",
        "\n",
        "The results show a clear improvement when using multi-modal embeddings, compared to just using the KG embeddings.\n",
        "\n",
        "In [notebook 08](https://colab.research.google.com/github/HybridNLP2018/tutorial/blob/master/08_scientific_information_management.ipynb) of this tutorial you will see another possible way of exploiting cross-modality."
      ]
    },
    {
      "metadata": {
        "id": "THw9FuX6YXC3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}