{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h-JvXRJ42B1a"
   },
   "source": [
    "# Learn and evaluate a classifier for scigraph articles using surface form annotations.\n",
    "Articles are classified in any of the 22 first level categories in which they are categorized in Scigprah. Previously we have extracted from scrigraph the papers published in 2011 and for each paper we consider only the text in the title and the abstract. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aDz8cbtR2B1r"
   },
   "source": [
    "## Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aeyZFrue2B12"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LSTM\n",
    "from keras.models import Model, Sequential\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "from random import sample\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import h5py\n",
    "import mmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nz9jiJ5tRK-n"
   },
   "source": [
    "# Download data: surface form embeddings, and scigraph papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bYqnsQ-JRRcZ"
   },
   "source": [
    "## Downloading data from google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "KW64JOnv2B2p",
    "outputId": "b7145449-7e66-4829-cb89-59f6b1b5cad4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.12.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.28.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.21.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "_oeVQMIX2B3G",
    "outputId": "9385d95c-e43a-4f94-a0d1-d232da8e2e44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1MRL2mYnJUb-qGitAZ53BFeNi4HLyqKlN\n",
      "To: /content/data-embeddings.zip\n",
      "1.13GB [00:45, 24.8MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data-embeddings.zip'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "url = 'https://drive.google.com/uc?id=1MRL2mYnJUb-qGitAZ53BFeNi4HLyqKlN'\n",
    "out = 'data-embeddings.zip'\n",
    "gdown.download(url,out,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D_dms1mw2B3Z"
   },
   "source": [
    "unzip the content and set the variables that points to the data and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "_IkhCa-02B3g",
    "outputId": "84f515f7-ea61-4945-f8fb-8c1151500f31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data-embeddings.zip\n",
      "  inflating: data/scigraph-2011-sf.json  \n",
      "  inflating: embeddings/row_embedding.tsv  \n"
     ]
    }
   ],
   "source": [
    "!unzip data-embeddings.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1rRAe7OW2B33"
   },
   "outputs": [],
   "source": [
    "dataset_file=\"data/scigraph-2011-sf.json\"\n",
    "embeddings_file=\"embeddings/row_embedding.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gd0sy8P2Rav5"
   },
   "source": [
    "## Read and prepare the classification dataset\n",
    "To speed up the classifier learning process we take a sampe of the whole dataset. If you want to use the whole dataset please comment the second-to-last line below. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "xPFhyVvXPsFb",
    "outputId": "3e85a7a5-203d-434e-e0c4-9c0add287f6b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extracting labels: 100%|██████████| 187795/187795 [00:00<00:00, 350375.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10000 papers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sample_size = 10000\n",
    "texts = []\n",
    "labels_index = {}\n",
    "labels = []\n",
    "word_index = {}\n",
    "\n",
    "# Read the articles dataset that will be used to train and validate the model.\n",
    "with open(dataset_file, \"r\", encoding=\"utf-8\", errors=\"surrogatepass\") as file:\n",
    "  dataset = json.load(file)\n",
    "\n",
    "file.close()\n",
    "\n",
    "#Prepare data\n",
    "for doc in tqdm(dataset,total = len(dataset), desc=\"extracting labels\") :\n",
    "  # Extract the 2-number field code, that is, the most general one.\n",
    "  fields = [x for x in doc[\"fieldcodes\"] if len(x)==2]\n",
    "  label_ids = set()\n",
    "  for field in fields:\n",
    "      # Check if the field is already stored and if not, assign a new label to it.\n",
    "      if field not in labels_index:\n",
    "          label_id = len(labels_index)\n",
    "          labels_index[field] = label_id\n",
    "      else:\n",
    "          label_id = labels_index[field]\n",
    "      # Add the corresponding field label\n",
    "      label_ids.add(label_id)\n",
    "  labels.append(label_ids)\n",
    "  # Extract the title and abstract of each article\n",
    "  texts.append(doc[\"sf\"])\n",
    "\n",
    "#To speed up the training process we obtain a sample of sample_size of the data. \n",
    "#To work with the full dataset comment the line below\n",
    "labels, texts = zip(*sample(list(zip(labels, texts)), sample_size))\n",
    "print('\\n'+str(len(texts))+' papers')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iKBKIFvWi9mx"
   },
   "source": [
    "#### get data and label tensor, plus fkold (using tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "CTirlvDyjHWJ",
    "outputId": "9f04972f-1032-4ac8-cd82-07bc16105a4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39999 unique tokens.\n",
      "Shape of data tensor: (10000, 1000)\n",
      "Shape of label tensor: (10000, 22)\n",
      "Found 39999 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "max_nb_words = 40000\n",
    "max_sequence_length = 1000\n",
    "#estandar keras tokenizer filters except the + symbol which is used in our sf to glue multiword expressions\n",
    "tokenizer_filters = '!\"#$%&()*,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "\n",
    "# Tokenize the sentences of all the articles\n",
    "tokenizer = Tokenizer(num_words=max_nb_words, filters=tokenizer_filters)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# Get the vocabulary index\n",
    "word_index = { w:c for (w,c) in tokenizer.word_index.items() if c < max_nb_words}\n",
    "\n",
    "print(\"Found %s unique tokens.\" % len(word_index))\n",
    "\n",
    "# Fit the sequences into the maximum length\n",
    "data = pad_sequences(sequences, maxlen=max_sequence_length, padding=\"post\", truncating=\"post\")\n",
    "print(\"Shape of data tensor:\", data.shape)\n",
    "\n",
    "# Transform the labels into a binary vector, with one element for each category\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_cat = mlb.fit_transform(labels)\n",
    "\n",
    "print(\"Shape of label tensor:\", labels_cat.shape)\n",
    "\n",
    "print(\"Found %s unique tokens.\" % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sg1mLl8y6rH4"
   },
   "source": [
    "Glance at the vocabulary gathered by the tokenizer. Note that surface forms of multiword expression use the + symbol to concatenate the single words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "colab_type": "code",
    "id": "q5hWtVC72B5H",
    "outputId": "fbdf8a95-080b-4669-d28f-8b5c2151a297"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['moseri',\n",
       " 'gilbert',\n",
       " 'acanthocephalan',\n",
       " 'obscurus',\n",
       " 'rbcs',\n",
       " 'inelastic+collision',\n",
       " 'percutaneous+coronary+intervention',\n",
       " 'october+2006',\n",
       " 'pisaura',\n",
       " 'mirabilis',\n",
       " 'slits',\n",
       " 'polaritons',\n",
       " 'spps',\n",
       " 'cell+division+cycle',\n",
       " 'side+effect',\n",
       " 'photochemical+reaction',\n",
       " 'sulfosalicylaldehyde',\n",
       " 'displace',\n",
       " 'israeli+ibd',\n",
       " 'electrophiles']"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word_index.keys())[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AfnvX-ymRmpc"
   },
   "source": [
    "## Surface form embeddings\n",
    "In the following we use pre-trained vecisigrafo (Surface form) embeddings learned from scigraph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "prFKwyI8FhmP"
   },
   "source": [
    "### Load vecsigrafo embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "uJ1X6drAYOEt",
    "outputId": "9dbe83fc-a4fa-4270-ebd1-69f42e5cdb2e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embeddings file:   0%|          | 1302/692224 [00:00<00:53, 13014.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading fileembeddings/row_embedding.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embeddings file: 100%|██████████| 692224/692224 [00:48<00:00, 14275.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 692214 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dimensions = 300\n",
    "\n",
    "def get_num_lines(file_path):\n",
    "    fp = open(file_path, \"r+\")\n",
    "    buf = mmap.mmap(fp.fileno(), 0)\n",
    "    lines = 0\n",
    "    while buf.readline():\n",
    "        lines += 1\n",
    "    return lines\n",
    "\n",
    "file_size = get_num_lines (embeddings_file)\n",
    "print(\"loading file\"+embeddings_file)\n",
    "\n",
    "# Load the word embeddings\n",
    "file = open(embeddings_file, \"r\", encoding=\"utf-8\", errors=\"surrogatepass\")\n",
    "embeddings_index = {}\n",
    "#for line in tqdm(file, total = file_size, desc=\"processing lines in embeddings file\") :      \n",
    "\n",
    "with open(embeddings_file) as infile:\n",
    "    for line in tqdm(infile, total = file_size, desc=\"Embeddings file\") :\n",
    "        values = line.split()\n",
    "        wordlimit=len(values)-dimensions\n",
    "        vector = np.asarray(values[wordlimit:], dtype='float32')\n",
    "        word = values[0]\n",
    "        index=0\n",
    "        for value in values[1:wordlimit]:\n",
    "            word = word + \"+\"+value\n",
    "        embeddings_index[word] = vector        \n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8CdQbE049ck0"
   },
   "source": [
    "Glance at some of the surface forms contained in the embeddings files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "colab_type": "code",
    "id": "umgoH27PdNXX",
    "outputId": "e9d7e560-d8de-4ffa-ce00-fd38181bc85f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['irrigated', 'sequelae', 'chronic+diseases', 'landolt-börnstein+homepage+volume+iv', 'tick', 'vte', 'until+now', 'bootstrap', '2+%', 'authentic', 'single-crystal', 'social+sciences', 'streptomyces', 'florida', 'revisited', 'septic', 'vertically', 'object-oriented', 'ast', 'inevitably', 'proteasome', 'relatedness', 'rms', 'sixth', 'gesture', 'microalgae', 'at+large', 'constrain', 'locomotor', 'gather', 'rituximab', 'interspecific', 'k.', 'cows', 'minutes', '75+%', 'norwegian', 'resource+management', 'soliton', 'anodic', 'everyone', 'implements', 'outsourcing', 'incoming', 'nationally', 'traction', 'workpiece', 'oscillators', 'bear', 'empire', 'breeds', 'ppar_', 'cerebrovascular', 'striatum', 'propositions', 'seminal', 'tha', 'compressive+strength', 'specialty', 'fiscal', 'h2s', 'methodspatients', 'replicated', 'bus', 'glial', 'goats', 'obligations', 'scanner', 'epitope', 'input+data', 'om', 'electron+beam', 'surface+layer', 'diesel', 'air+quality', 'empowerment', 'nocturnal', 'focus+groups', 'prototypes', 'bw', 'synchronized', 'july', 'revascularization', 'radiography', 'observables', 'acidification', 'h_', 'drain', 'exam', 'manufacturer', 'critics', 'solid+solution', 'detects', 'pharmacologic', '27%', 'ductile', 'laplace', '0.94', 's2', '0.92']\n"
     ]
    }
   ],
   "source": [
    "l=[w for w,e in embeddings_index.items()]\n",
    "print(l[10000:10100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bs673ts78-cM"
   },
   "source": [
    "## Create the Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "Iqdhnx_w87FI",
    "outputId": "eb27d8ed-83b4-41d4-e581-431a9f92bb6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim ->300\n",
      "word_index len ->40000\n",
      "last position in the dictionary ->39999\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a matrix with all the embeddings corresponding to all the vocabulary words\n",
    "embedding_dimensions = len(list(embeddings_index.values())[0])\n",
    "\n",
    "#dictionary_size = len(word_index) \n",
    "dictionary_size = list(word_index.values())[-1]\n",
    "\n",
    "print(\"dim ->\"+str(embedding_dimensions))\n",
    "print(\"word_index len ->\"+str(len(word_index) + 1))\n",
    "print(\"last position in the dictionary ->\"+ str(dictionary_size))\n",
    "\n",
    "embedding_matrix = np.zeros((dictionary_size + 1, embedding_dimensions))\n",
    "for word, i in word_index.items():    \n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:        \n",
    "        # Words not found in the embedding index will be all-zeros        \n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "# Create an embedding layer based on the embedding matrix\n",
    "# This layer is not trainable: the embeddings will not be changed during training time\n",
    "embedding_layer = Embedding(dictionary_size + 1,\n",
    "                                 embedding_dimensions,\n",
    "                                 weights = [embedding_matrix],\n",
    "                                 input_length = max_sequence_length,\n",
    "                                 trainable = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUmTJMejRs7t"
   },
   "source": [
    "## Train a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PvEaK21tQGgP",
    "outputId": "bbbe0984-454b-4adb-d3e6-47dca71189b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 8s 902us/step - loss: 0.1578 - categorical_accuracy: 0.3662 - val_loss: 0.1181 - val_categorical_accuracy: 0.5390\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 3s 299us/step - loss: 0.0991 - categorical_accuracy: 0.5926 - val_loss: 0.0959 - val_categorical_accuracy: 0.5740\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 3s 300us/step - loss: 0.0829 - categorical_accuracy: 0.6673 - val_loss: 0.0824 - val_categorical_accuracy: 0.6540\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 3s 301us/step - loss: 0.0734 - categorical_accuracy: 0.7080 - val_loss: 0.0835 - val_categorical_accuracy: 0.6620\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 3s 302us/step - loss: 0.0653 - categorical_accuracy: 0.7396 - val_loss: 0.0808 - val_categorical_accuracy: 0.6750\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8595    0.9007    0.8796       292\n",
      "           1     0.8871    0.3929    0.5446       140\n",
      "           2     0.7864    0.7788    0.7826       104\n",
      "           3     1.0000    0.0526    0.1000        38\n",
      "           4     0.8214    0.6133    0.7023        75\n",
      "           5     0.6667    0.7742    0.7164        31\n",
      "           6     0.7861    0.8395    0.8119       162\n",
      "           7     0.0000    0.0000    0.0000        18\n",
      "           8     0.2857    0.3333    0.3077         6\n",
      "           9     0.7778    0.1061    0.1867        66\n",
      "          10     0.7105    0.5294    0.6067        51\n",
      "          11     0.0000    0.0000    0.0000        19\n",
      "          12     0.0000    0.0000    0.0000         6\n",
      "          13     0.4103    0.8889    0.5614        36\n",
      "          14     0.2857    0.2222    0.2500         9\n",
      "          15     0.0000    0.0000    0.0000         3\n",
      "          16     0.0000    0.0000    0.0000        10\n",
      "          17     0.0000    0.0000    0.0000        11\n",
      "          18     0.0000    0.0000    0.0000         1\n",
      "          19     0.0000    0.0000    0.0000        12\n",
      "          20     0.0000    0.0000    0.0000         0\n",
      "          21     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.7719    0.6211    0.6884      1090\n",
      "   macro avg     0.3762    0.2924    0.2932      1090\n",
      "weighted avg     0.7442    0.6211    0.6351      1090\n",
      " samples avg     0.6258    0.6290    0.6184      1090\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 3s 338us/step - loss: 0.1616 - categorical_accuracy: 0.3561 - val_loss: 0.1222 - val_categorical_accuracy: 0.4420\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 3s 303us/step - loss: 0.1032 - categorical_accuracy: 0.5799 - val_loss: 0.1042 - val_categorical_accuracy: 0.5880\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 3s 304us/step - loss: 0.0871 - categorical_accuracy: 0.6518 - val_loss: 0.0801 - val_categorical_accuracy: 0.6760\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 3s 303us/step - loss: 0.0762 - categorical_accuracy: 0.6930 - val_loss: 0.0771 - val_categorical_accuracy: 0.6900\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 3s 304us/step - loss: 0.0678 - categorical_accuracy: 0.7308 - val_loss: 0.0861 - val_categorical_accuracy: 0.6480\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8754    0.8613    0.8683       310\n",
      "           1     0.8261    0.3140    0.4551       121\n",
      "           2     0.5353    0.8835    0.6667       103\n",
      "           3     1.0000    0.0278    0.0541        36\n",
      "           4     0.7500    0.4390    0.5538        82\n",
      "           5     0.7381    0.7561    0.7470        41\n",
      "           6     0.9043    0.4802    0.6273       177\n",
      "           7     0.0000    0.0000    0.0000        15\n",
      "           8     0.0000    0.0000    0.0000        17\n",
      "           9     0.5323    0.6226    0.5739        53\n",
      "          10     0.6000    0.5581    0.5783        43\n",
      "          11     1.0000    0.0500    0.0952        20\n",
      "          12     0.0000    0.0000    0.0000         4\n",
      "          13     0.6667    0.5833    0.6222        24\n",
      "          14     0.0000    0.0000    0.0000        14\n",
      "          15     0.0000    0.0000    0.0000         7\n",
      "          16     1.0000    0.2000    0.3333         5\n",
      "          17     0.0000    0.0000    0.0000         7\n",
      "          18     0.0000    0.0000    0.0000         2\n",
      "          19     0.0000    0.0000    0.0000        11\n",
      "          20     0.0000    0.0000    0.0000         0\n",
      "          21     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.7485    0.5696    0.6469      1092\n",
      "   macro avg     0.4285    0.2625    0.2807      1092\n",
      "weighted avg     0.7411    0.5696    0.6005      1092\n",
      " samples avg     0.6030    0.5888    0.5899      1092\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 3s 348us/step - loss: 0.1581 - categorical_accuracy: 0.3760 - val_loss: 0.1269 - val_categorical_accuracy: 0.4890\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 3s 309us/step - loss: 0.0989 - categorical_accuracy: 0.5974 - val_loss: 0.1060 - val_categorical_accuracy: 0.5540\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 3s 307us/step - loss: 0.0823 - categorical_accuracy: 0.6716 - val_loss: 0.0946 - val_categorical_accuracy: 0.6150\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 3s 306us/step - loss: 0.0725 - categorical_accuracy: 0.7104 - val_loss: 0.0918 - val_categorical_accuracy: 0.6250\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 3s 308us/step - loss: 0.0655 - categorical_accuracy: 0.7313 - val_loss: 0.0836 - val_categorical_accuracy: 0.6640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9529    0.7642    0.8482       318\n",
      "           1     0.7143    0.6115    0.6589       139\n",
      "           2     0.6284    0.8611    0.7266       108\n",
      "           3     0.0000    0.0000    0.0000        37\n",
      "           4     0.5263    0.7692    0.6250        65\n",
      "           5     0.8000    0.2963    0.4324        27\n",
      "           6     0.8380    0.7532    0.7933       158\n",
      "           7     0.0000    0.0000    0.0000        12\n",
      "           8     0.2500    0.3529    0.2927        17\n",
      "           9     0.8750    0.1228    0.2154        57\n",
      "          10     0.9167    0.2245    0.3607        49\n",
      "          11     0.4444    0.1739    0.2500        23\n",
      "          12     0.0000    0.0000    0.0000         4\n",
      "          13     0.6154    0.2759    0.3810        29\n",
      "          14     0.0000    0.0000    0.0000        12\n",
      "          15     0.0000    0.0000    0.0000         3\n",
      "          16     0.6000    0.3750    0.4615         8\n",
      "          17     0.0000    0.0000    0.0000         6\n",
      "          18     0.0000    0.0000    0.0000         6\n",
      "          19     0.0000    0.0000    0.0000         4\n",
      "          20     0.0000    0.0000    0.0000         0\n",
      "          21     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.7583    0.5887    0.6629      1082\n",
      "   macro avg     0.3710    0.2537    0.2748      1082\n",
      "weighted avg     0.7304    0.5887    0.6218      1082\n",
      " samples avg     0.6070    0.6008    0.5982      1082\n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 3s 363us/step - loss: 0.1624 - categorical_accuracy: 0.3517 - val_loss: 0.1051 - val_categorical_accuracy: 0.5720\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 3s 308us/step - loss: 0.1003 - categorical_accuracy: 0.5826 - val_loss: 0.0936 - val_categorical_accuracy: 0.6280\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 3s 309us/step - loss: 0.0836 - categorical_accuracy: 0.6620 - val_loss: 0.0815 - val_categorical_accuracy: 0.6670\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 3s 310us/step - loss: 0.0734 - categorical_accuracy: 0.7082 - val_loss: 0.0878 - val_categorical_accuracy: 0.6780\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 3s 309us/step - loss: 0.0662 - categorical_accuracy: 0.7336 - val_loss: 0.0764 - val_categorical_accuracy: 0.7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8907    0.8445    0.8670       328\n",
      "           1     0.7545    0.6336    0.6888       131\n",
      "           2     0.7969    0.5152    0.6258        99\n",
      "           3     0.4923    0.7619    0.5981        42\n",
      "           4     0.6449    0.8023    0.7150        86\n",
      "           5     0.7500    0.7241    0.7368        29\n",
      "           6     0.8403    0.7423    0.7883       163\n",
      "           7     0.0000    0.0000    0.0000        14\n",
      "           8     0.0000    0.0000    0.0000        22\n",
      "           9     0.5455    0.5769    0.5607        52\n",
      "          10     0.6364    0.7000    0.6667        40\n",
      "          11     0.0000    0.0000    0.0000        15\n",
      "          12     0.0000    0.0000    0.0000         5\n",
      "          13     1.0000    0.0714    0.1333        28\n",
      "          14     0.0000    0.0000    0.0000        11\n",
      "          15     0.0000    0.0000    0.0000         4\n",
      "          16     0.2308    0.5000    0.3158         6\n",
      "          17     0.0000    0.0000    0.0000         5\n",
      "          18     0.0000    0.0000    0.0000         9\n",
      "          19     0.0000    0.0000    0.0000         6\n",
      "          20     0.0000    0.0000    0.0000         0\n",
      "          21     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.7587    0.6548    0.7029      1095\n",
      "   macro avg     0.3446    0.3124    0.3044      1095\n",
      "weighted avg     0.7196    0.6548    0.6708      1095\n",
      " samples avg     0.6760    0.6772    0.6676      1095\n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 3s 366us/step - loss: 0.1548 - categorical_accuracy: 0.3730 - val_loss: 0.1092 - val_categorical_accuracy: 0.5370\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 3s 312us/step - loss: 0.0996 - categorical_accuracy: 0.5874 - val_loss: 0.0942 - val_categorical_accuracy: 0.5850\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 3s 313us/step - loss: 0.0842 - categorical_accuracy: 0.6588 - val_loss: 0.0890 - val_categorical_accuracy: 0.6340\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 3s 310us/step - loss: 0.0734 - categorical_accuracy: 0.7087 - val_loss: 0.0973 - val_categorical_accuracy: 0.6210\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 3s 312us/step - loss: 0.0660 - categorical_accuracy: 0.7373 - val_loss: 0.0782 - val_categorical_accuracy: 0.6610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8953    0.8604    0.8775       308\n",
      "           1     0.8462    0.3259    0.4706       135\n",
      "           2     0.6557    0.7692    0.7080       104\n",
      "           3     0.4118    0.2692    0.3256        26\n",
      "           4     0.6316    0.6076    0.6194        79\n",
      "           5     0.5143    0.6667    0.5806        27\n",
      "           6     0.9175    0.5298    0.6717       168\n",
      "           7     0.0000    0.0000    0.0000        21\n",
      "           8     0.8889    0.5000    0.6400        16\n",
      "           9     0.6667    0.5098    0.5778        51\n",
      "          10     0.8056    0.5472    0.6517        53\n",
      "          11     0.0000    0.0000    0.0000        17\n",
      "          12     0.0000    0.0000    0.0000         7\n",
      "          13     0.7500    0.0938    0.1667        32\n",
      "          14     0.0000    0.0000    0.0000        14\n",
      "          15     0.0000    0.0000    0.0000         3\n",
      "          16     1.0000    0.4545    0.6250        11\n",
      "          17     0.0000    0.0000    0.0000         6\n",
      "          18     0.0000    0.0000    0.0000         5\n",
      "          19     0.0000    0.0000    0.0000         5\n",
      "          20     0.0000    0.0000    0.0000         0\n",
      "          21     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.7893    0.5717    0.6631      1088\n",
      "   macro avg     0.4083    0.2788    0.3143      1088\n",
      "weighted avg     0.7470    0.5717    0.6248      1088\n",
      " samples avg     0.6150    0.5907    0.5972      1088\n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 3s 374us/step - loss: 0.1527 - categorical_accuracy: 0.3910 - val_loss: 0.1293 - val_categorical_accuracy: 0.4730\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 3s 312us/step - loss: 0.0982 - categorical_accuracy: 0.5972 - val_loss: 0.1095 - val_categorical_accuracy: 0.5680\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 3s 313us/step - loss: 0.0834 - categorical_accuracy: 0.6632 - val_loss: 0.0922 - val_categorical_accuracy: 0.6440\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 3s 313us/step - loss: 0.0723 - categorical_accuracy: 0.7118 - val_loss: 0.0846 - val_categorical_accuracy: 0.6670\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 3s 315us/step - loss: 0.0658 - categorical_accuracy: 0.7343 - val_loss: 0.0867 - val_categorical_accuracy: 0.6540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7455    0.9452    0.8336       310\n",
      "           1     0.9512    0.3145    0.4727       124\n",
      "           2     0.6496    0.7170    0.6816       106\n",
      "           3     0.6452    0.5882    0.6154        34\n",
      "           4     0.7400    0.4744    0.5781        78\n",
      "           5     0.9167    0.2895    0.4400        38\n",
      "           6     0.8759    0.7643    0.8163       157\n",
      "           7     0.0000    0.0000    0.0000        21\n",
      "           8     1.0000    0.2400    0.3871        25\n",
      "           9     0.5667    0.3036    0.3953        56\n",
      "          10     0.4643    0.6190    0.5306        42\n",
      "          11     0.3889    0.4118    0.4000        17\n",
      "          12     0.0000    0.0000    0.0000         7\n",
      "          13     0.4737    0.3600    0.4091        25\n",
      "          14     0.0000    0.0000    0.0000        12\n",
      "          15     0.0000    0.0000    0.0000        12\n",
      "          16     1.0000    0.2500    0.4000        12\n",
      "          17     0.0000    0.0000    0.0000         4\n",
      "          18     0.0000    0.0000    0.0000         4\n",
      "          19     1.0000    0.0714    0.1333        14\n",
      "          20     0.0000    0.0000    0.0000         2\n",
      "          21     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.7276    0.6045    0.6604      1100\n",
      "   macro avg     0.4735    0.2886    0.3224      1100\n",
      "weighted avg     0.7187    0.6045    0.6163      1100\n",
      " samples avg     0.6212    0.6195    0.6105      1100\n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 3s 387us/step - loss: 0.1588 - categorical_accuracy: 0.3757 - val_loss: 0.1109 - val_categorical_accuracy: 0.5420\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 3s 315us/step - loss: 0.0998 - categorical_accuracy: 0.5846 - val_loss: 0.1055 - val_categorical_accuracy: 0.5560\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 3s 316us/step - loss: 0.0832 - categorical_accuracy: 0.6588 - val_loss: 0.1007 - val_categorical_accuracy: 0.5900\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 3s 316us/step - loss: 0.0745 - categorical_accuracy: 0.7003 - val_loss: 0.0792 - val_categorical_accuracy: 0.6740\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 3s 319us/step - loss: 0.0664 - categorical_accuracy: 0.7330 - val_loss: 0.0796 - val_categorical_accuracy: 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8806    0.8750    0.8778       312\n",
      "           1     0.6084    0.7768    0.6824       112\n",
      "           2     0.7778    0.5138    0.6188       109\n",
      "           3     1.0000    0.0541    0.1026        37\n",
      "           4     0.6456    0.7969    0.7133        64\n",
      "           5     0.8500    0.4857    0.6182        35\n",
      "           6     0.8526    0.4880    0.6207       166\n",
      "           7     0.0000    0.0000    0.0000        12\n",
      "           8     0.0000    0.0000    0.0000        26\n",
      "           9     0.9286    0.1940    0.3210        67\n",
      "          10     0.7714    0.5510    0.6429        49\n",
      "          11     1.0000    0.1200    0.2143        25\n",
      "          12     0.0000    0.0000    0.0000         7\n",
      "          13     1.0000    0.1667    0.2857        30\n",
      "          14     0.0000    0.0000    0.0000        13\n",
      "          15     0.0000    0.0000    0.0000         3\n",
      "          16     0.0000    0.0000    0.0000        14\n",
      "          17     0.0000    0.0000    0.0000         2\n",
      "          18     0.0000    0.0000    0.0000         5\n",
      "          19     0.0000    0.0000    0.0000         9\n",
      "          20     0.0000    0.0000    0.0000         0\n",
      "          21     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.7905    0.5606    0.6560      1097\n",
      "   macro avg     0.4234    0.2283    0.2590      1097\n",
      "weighted avg     0.7587    0.5606    0.6005      1097\n",
      " samples avg     0.6065    0.5826    0.5884      1097\n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 4s 395us/step - loss: 0.1588 - categorical_accuracy: 0.3712 - val_loss: 0.1161 - val_categorical_accuracy: 0.5240\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 3s 319us/step - loss: 0.1011 - categorical_accuracy: 0.5824 - val_loss: 0.0991 - val_categorical_accuracy: 0.6210\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 3s 320us/step - loss: 0.0863 - categorical_accuracy: 0.6510 - val_loss: 0.0863 - val_categorical_accuracy: 0.6550\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 3s 318us/step - loss: 0.0753 - categorical_accuracy: 0.6997 - val_loss: 0.0845 - val_categorical_accuracy: 0.6740\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 3s 319us/step - loss: 0.0671 - categorical_accuracy: 0.7293 - val_loss: 0.0785 - val_categorical_accuracy: 0.6920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9451    0.8543    0.8974       302\n",
      "           1     0.7179    0.4786    0.5744       117\n",
      "           2     0.6950    0.8522    0.7656       115\n",
      "           3     0.4211    0.7619    0.5424        42\n",
      "           4     0.6349    0.6250    0.6299        64\n",
      "           5     0.8571    0.2791    0.4211        43\n",
      "           6     0.8923    0.6480    0.7508       179\n",
      "           7     0.0000    0.0000    0.0000        12\n",
      "           8     0.0000    0.0000    0.0000        20\n",
      "           9     0.7241    0.4118    0.5250        51\n",
      "          10     0.9091    0.2041    0.3333        49\n",
      "          11     0.0000    0.0000    0.0000        14\n",
      "          12     0.0000    0.0000    0.0000         8\n",
      "          13     0.6000    0.0750    0.1333        40\n",
      "          14     0.0000    0.0000    0.0000        14\n",
      "          15     0.0000    0.0000    0.0000         3\n",
      "          16     0.0000    0.0000    0.0000         9\n",
      "          17     0.0000    0.0000    0.0000         8\n",
      "          18     0.0000    0.0000    0.0000         3\n",
      "          19     0.0000    0.0000    0.0000         9\n",
      "          20     0.0000    0.0000    0.0000         0\n",
      "          21     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.7878    0.5862    0.6722      1102\n",
      "   macro avg     0.3362    0.2359    0.2533      1102\n",
      "weighted avg     0.7348    0.5862    0.6264      1102\n",
      " samples avg     0.6220    0.6073    0.6076      1102\n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 4s 408us/step - loss: 0.1556 - categorical_accuracy: 0.3842 - val_loss: 0.1062 - val_categorical_accuracy: 0.5420\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 3s 322us/step - loss: 0.0986 - categorical_accuracy: 0.5941 - val_loss: 0.0902 - val_categorical_accuracy: 0.6100\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 3s 321us/step - loss: 0.0826 - categorical_accuracy: 0.6653 - val_loss: 0.0895 - val_categorical_accuracy: 0.6230\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 3s 322us/step - loss: 0.0733 - categorical_accuracy: 0.7051 - val_loss: 0.0768 - val_categorical_accuracy: 0.7080\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 3s 321us/step - loss: 0.0659 - categorical_accuracy: 0.7370 - val_loss: 0.0900 - val_categorical_accuracy: 0.6300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9536    0.7459    0.8370       303\n",
      "           1     0.8913    0.2847    0.4316       144\n",
      "           2     0.7937    0.4902    0.6061       102\n",
      "           3     0.4386    0.8621    0.5814        29\n",
      "           4     0.3242    0.9219    0.4797        64\n",
      "           5     0.9000    0.6000    0.7200        30\n",
      "           6     0.7725    0.8670    0.8170       188\n",
      "           7     0.0000    0.0000    0.0000        16\n",
      "           8     0.8000    0.2105    0.3333        19\n",
      "           9     0.7297    0.4355    0.5455        62\n",
      "          10     0.8462    0.2075    0.3333        53\n",
      "          11     0.0000    0.0000    0.0000        13\n",
      "          12     0.0000    0.0000    0.0000         8\n",
      "          13     1.0000    0.1304    0.2308        23\n",
      "          14     0.0000    0.0000    0.0000         9\n",
      "          15     0.0000    0.0000    0.0000         5\n",
      "          16     0.0000    0.0000    0.0000         9\n",
      "          17     0.0000    0.0000    0.0000         8\n",
      "          18     0.0000    0.0000    0.0000         1\n",
      "          19     0.0000    0.0000    0.0000         6\n",
      "          20     0.0000    0.0000    0.0000         0\n",
      "          21     0.0000    0.0000    0.0000         1\n",
      "\n",
      "   micro avg     0.7174    0.5737    0.6375      1093\n",
      "   macro avg     0.3841    0.2616    0.2689      1093\n",
      "weighted avg     0.7614    0.5737    0.6070      1093\n",
      " samples avg     0.5985    0.5907    0.5862      1093\n",
      "\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 [==============================] - 4s 417us/step - loss: 0.1590 - categorical_accuracy: 0.3706 - val_loss: 0.1178 - val_categorical_accuracy: 0.5180\n",
      "Epoch 2/5\n",
      "9000/9000 [==============================] - 3s 325us/step - loss: 0.0991 - categorical_accuracy: 0.5889 - val_loss: 0.0955 - val_categorical_accuracy: 0.6120\n",
      "Epoch 3/5\n",
      "9000/9000 [==============================] - 3s 325us/step - loss: 0.0827 - categorical_accuracy: 0.6598 - val_loss: 0.0987 - val_categorical_accuracy: 0.6020\n",
      "Epoch 4/5\n",
      "9000/9000 [==============================] - 3s 324us/step - loss: 0.0722 - categorical_accuracy: 0.7090 - val_loss: 0.0846 - val_categorical_accuracy: 0.6800\n",
      "Epoch 5/5\n",
      "9000/9000 [==============================] - 3s 324us/step - loss: 0.0652 - categorical_accuracy: 0.7344 - val_loss: 0.0818 - val_categorical_accuracy: 0.6970\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9726    0.6574    0.7845       324\n",
      "           1     0.5909    0.6594    0.6233       138\n",
      "           2     0.8148    0.6535    0.7253       101\n",
      "           3     1.0000    0.1429    0.2500        42\n",
      "           4     0.6667    0.6452    0.6557        62\n",
      "           5     0.8421    0.4571    0.5926        35\n",
      "           6     0.8391    0.8111    0.8249       180\n",
      "           7     0.0000    0.0000    0.0000        12\n",
      "           8     0.7143    0.2941    0.4167        17\n",
      "           9     0.6441    0.6667    0.6552        57\n",
      "          10     0.6136    0.6000    0.6067        45\n",
      "          11     0.0000    0.0000    0.0000        18\n",
      "          12     0.0000    0.0000    0.0000         4\n",
      "          13     0.6667    0.0769    0.1379        26\n",
      "          14     1.0000    0.0526    0.1000        19\n",
      "          15     0.0000    0.0000    0.0000         1\n",
      "          16     0.0000    0.0000    0.0000         6\n",
      "          17     0.0000    0.0000    0.0000        13\n",
      "          18     0.0000    0.0000    0.0000         4\n",
      "          19     0.0000    0.0000    0.0000         5\n",
      "          20     0.0000    0.0000    0.0000         0\n",
      "          21     0.0000    0.0000    0.0000         3\n",
      "\n",
      "   micro avg     0.7872    0.5854    0.6715      1112\n",
      "   macro avg     0.4257    0.2599    0.2897      1112\n",
      "weighted avg     0.7694    0.5854    0.6394      1112\n",
      " samples avg     0.6360    0.6123    0.6163      1112\n",
      "\n",
      "Precision: 0.7425 (+/- 0.0163)\n",
      "Recall: 0.5916 (+/- 0.0270)\n",
      "F1 Score: 0.6243 (+/- 0.0200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "for train, test in kfold.split(data, labels_cat):  \n",
    "  # Define, train and validate the neural network model\n",
    "  sequence_input = Input(shape=(max_sequence_length,), dtype=\"int32\")\n",
    "  embedded_sequences = embedding_layer(sequence_input)\n",
    "  x = Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
    "  x = MaxPooling1D(5)(x)\n",
    "  x = Conv1D(128, 5, activation=\"relu\")(x)\n",
    "  x = MaxPooling1D(5)(x)\n",
    "  x = Conv1D(128, 5, activation=\"relu\")(x)\n",
    "  x = MaxPooling1D(35)(x)\n",
    "  x = Flatten()(x)\n",
    "  #x = Dropout(0.2)(x)\n",
    "  x = Dense(128, activation=\"relu\")(x)\n",
    "  #x = Dropout(0.2)(x)\n",
    "  preds = Dense(len(labels_index), activation=\"sigmoid\")(x)\n",
    "  model = Model(sequence_input, preds)\n",
    "  model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[categorical_accuracy])\n",
    "#print (model.summary())\n",
    "  model.fit(data[train], labels_cat[train], validation_data=(data[test], labels_cat[test]),\n",
    "            epochs=5, batch_size=128)\n",
    "\n",
    "  # Evaluate the model assigning zeros and ones according to a threshold\n",
    "  pred = model.predict(data[test], batch_size=128)\n",
    "  pred[pred >= 0.5] = 1\n",
    "  pred[pred < 0.5] = 0\n",
    "  print(classification_report(labels_cat[test], pred, digits=4))\n",
    "  precisions.append(precision_score(labels_cat[test], pred, average=\"weighted\"))\n",
    "  recalls.append(recall_score(labels_cat[test], pred, average=\"weighted\"))\n",
    "  f1s.append(f1_score(labels_cat[test], pred, average=\"weighted\"))\n",
    "print(\"Precision: %.4f (+/- %.4f)\" % (np.mean(precisions), np.std(precisions)))\n",
    "print(\"Recall: %.4f (+/- %.4f)\" % (np.mean(recalls), np.std(recalls)))\n",
    "print(\"F1 Score: %.4f (+/- %.4f)\" % (np.mean(f1s), np.std(f1s)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Scigraph-sfAnnotations-CNN-classifier.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
